{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2799594,"sourceType":"datasetVersion","datasetId":1710176},{"sourceId":7066541,"sourceType":"datasetVersion","datasetId":4069026},{"sourceId":7553728,"sourceType":"datasetVersion","datasetId":4399484},{"sourceId":7554122,"sourceType":"datasetVersion","datasetId":4399695},{"sourceId":7570663,"sourceType":"datasetVersion","datasetId":4407360},{"sourceId":7570728,"sourceType":"datasetVersion","datasetId":4407395},{"sourceId":7570752,"sourceType":"datasetVersion","datasetId":4407407},{"sourceId":7578231,"sourceType":"datasetVersion","datasetId":4411634},{"sourceId":7579384,"sourceType":"datasetVersion","datasetId":4412092},{"sourceId":7613066,"sourceType":"datasetVersion","datasetId":4433352},{"sourceId":7613143,"sourceType":"datasetVersion","datasetId":4433396},{"sourceId":7613254,"sourceType":"datasetVersion","datasetId":4371594},{"sourceId":7613290,"sourceType":"datasetVersion","datasetId":4433498},{"sourceId":7698313,"sourceType":"datasetVersion","datasetId":4493190},{"sourceId":7702265,"sourceType":"datasetVersion","datasetId":4407342},{"sourceId":7710701,"sourceType":"datasetVersion","datasetId":4502366},{"sourceId":7775090,"sourceType":"datasetVersion","datasetId":4433145},{"sourceId":8467,"sourceType":"modelInstanceVersion","modelInstanceId":6691,"modelId":7601}],"dockerImageVersionId":30664,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center>Anomaly Detection In Surveillance Camera Using Machine Learning</center>\n","metadata":{}},{"cell_type":"markdown","source":"   # Preprocessing\n\nExtracting out the category labels","metadata":{}},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nimport os\nimport cv2\nimport pickle\nfrom tqdm import tqdm\nimport numpy as np\nimport random\n\ntest_dir = '/kaggle/input/ucf-crime-dataset/Test'\ntrain_dir = '/kaggle/input/ucf-crime-dataset/Train'\n\n# Define the categories and labels\ncategories_labels = {\n    'Fighting': 0, \n    'Shoplifting': 1, \n    'Abuse': 2, \n    'Arrest': 3, \n    'Shooting': 4, \n    'Robbery': 5, \n    'Explosion': 6,\n}\n\n\n\ndef load_data(base_dir, categories_labels):\n    data = []\n    \n    # Go through each category\n    for category, label in categories_labels.items():\n        # The path to the category directory\n        category_dir = os.path.join(base_dir, category)\n\n        # Make sure the directory exists\n        if os.path.isdir(category_dir):\n            # Go through each file in the directory\n            for filename in tqdm(os.listdir(category_dir), desc=f\"Loading {category}\"):\n                # Make sure the file is an image\n                if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n                    # The path to the image\n                    image_path = os.path.join(category_dir, filename)\n\n                    try:\n                        # Load the image\n                        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n\n                        # Resize the image\n                        image = cv2.resize(image, (50, 50))\n\n                        # Reshape the image to 4D array \n                        #(ImageDataGenerator requires 4D array)\n                        image = image.reshape((1,) + image.shape + (1,))\n\n                        # Add the image and its label to the data\n                        data.append([image, label])\n                    except Exception as e:\n                        print(f\"Error loading image {image_path}: {e}\")\n\n    return data\n\n# Load the training and test data\ntraining_data = load_data(train_dir, categories_labels)\ntest_data = load_data(test_dir, categories_labels)\n\n# Combine the training and test data\ntotal_data = training_data + test_data\n\nprint(f\"Loaded {len(total_data)} images.\")\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(training_data))\nprint(len(test_data))\nprint(len(total_data))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import np_utils\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\nfrom keras.layers import LSTM, TimeDistributed, Conv1D, MaxPooling1D\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import concatenate\nfrom keras.utils.vis_utils import plot_model\nfrom tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\nimport time\n\n\n# Initialize lists to store the images and the labels\nimages = []\nlabels = []\n\n# Go through each image and its label in the total_data\nfor image, label in total_data:\n    images.append(image)\n    labels.append(label)\n\n# Convert the lists into numpy arrays\nimages = np.array(images)\nlabels = np.array(labels)\nprint(images.shape)\n\n# Reshape images for LSTM\nimages_lstm = images.reshape(images.shape[0], -1, 1)  # Added third dimension for features\n\n# Set a seed for reproducibility\nseed = 51 #9 + 14 + 28\n\n# Split the data into training and testing sets for CNN\ntrain_images_cnn, test_images_cnn, train_labels_cnn, test_labels_cnn = train_test_split(images, labels, test_size=0.1, random_state=seed)\n\n# Split the data into training and testing sets for LSTM\ntrain_images_lstm, test_images_lstm, train_labels_lstm, test_labels_lstm = train_test_split(images_lstm, labels, test_size=0.1, random_state=seed)\n\n# Convert labels to categorical for CNN\ntrain_labels_cnn = np_utils.to_categorical(train_labels_cnn, len(categories_labels))\ntest_labels_cnn = np_utils.to_categorical(test_labels_cnn, len(categories_labels))\n\n# Convert labels to categorical for LSTM\ntrain_labels_lstm = np_utils.to_categorical(train_labels_lstm, len(categories_labels))\ntest_labels_lstm = np_utils.to_categorical(test_labels_lstm, len(categories_labels))\n\n# Remove the second dimension from your data\ntrain_images_cnn = np.squeeze(train_images_cnn, axis=1)\ntest_images_cnn = np.squeeze(test_images_cnn, axis=1)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Custom Model - CNN & LSTM","metadata":{}},{"cell_type":"code","source":"model_CNN = Sequential()\nmodel_CNN.add(Conv2D(64, kernel_size=(3, 3), padding='same', input_shape=(50, 50, 1)))\nmodel_CNN.add(LeakyReLU(alpha=0.1)) \nmodel_CNN.add(MaxPooling2D((2, 2), padding='same')) \nmodel_CNN.add(Dropout(0.25))\nmodel_CNN.add(Conv2D(128, (3, 3), padding='same')) \nmodel_CNN.add(LeakyReLU(alpha=0.1)) \nmodel_CNN.add(MaxPooling2D(pool_size=(2, 2), padding='same')) \nmodel_CNN.add(Dropout(0.25))\nmodel_CNN.add(Conv2D(256, (3, 3), padding='same'))\nmodel_CNN.add(LeakyReLU(alpha=0.1))\nmodel_CNN.add(MaxPooling2D(pool_size=(2, 2), padding='same')) \nmodel_CNN.add(Dropout(0.4))  \nmodel_CNN.add(Flatten()) \nmodel_CNN.add(Dense(256)) \nmodel_CNN.add(LeakyReLU(alpha=0.1))            \nmodel_CNN.add(Dropout(0.5)) \n\n# LSTM Model\nmodel_lstm = Sequential()\nmodel_lstm.add(LSTM(units = 8, return_sequences = True, input_shape = (2500, 1), activation='tanh'))\nmodel_lstm.add(LSTM(units = 8, return_sequences = True))\nmodel_lstm.add(Dense(4, activation='tanh'))\nmodel_lstm.add(Dropout(0.2))\nmodel_lstm.add(Flatten())\n\n# Combine CNN and LSTM model\nnb_classes = 6\ncombined = concatenate([model_CNN.output, model_lstm.output], axis=-1)\noutput = Dense(nb_classes, activation='softmax')(combined)\nmodel_final = Model(inputs=[model_CNN.input, model_lstm.input], outputs=output)\n\n# Plot and compile the model\nplot_model(model_final, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n\nmodel_final.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Callbacks\ncsv_logger = CSVLogger('training.log', separator=',', append=False)\nmc = ModelCheckpoint('CNN_LSTM.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n\n# Training\ntime1 = time.time()\nhistory = model_final.fit([train_images_cnn, train_images_lstm], train_labels_lstm, batch_size=1000, epochs=20, validation_data=([test_images_cnn, test_images_lstm], test_labels_lstm), callbacks=[mc, csv_logger])\nprint ((\"Training time=\", time.time()-time1))\n\n# Save training history\nnp.save(\"CNN_LSTM_history.npy\", history.history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<!-- #CNN Model\nmodel_CNN = Sequential()\nmodel_CNN.add(Conv2D(64, kernel_size=(3, 3), padding='same', input_shape=(50, 50, 1)))\nmodel_CNN.add(LeakyReLU(alpha=0.1)) \nmodel_CNN.add(MaxPooling2D((2, 2), padding='same')) \nmodel_CNN.add(Dropout(0.25))\nmodel_CNN.add(Conv2D(128, (3, 3), padding='same')) \nmodel_CNN.add(LeakyReLU(alpha=0.1)) \nmodel_CNN.add(MaxPooling2D(pool_size=(2, 2), padding='same')) \nmodel_CNN.add(Dropout(0.25))\nmodel_CNN.add(Conv2D(256, (3, 3), padding='same'))\nmodel_CNN.add(LeakyReLU(alpha=0.1))\nmodel_CNN.add(MaxPooling2D(pool_size=(2, 2), padding='same')) \nmodel_CNN.add(Dropout(0.4))  \nmodel_CNN.add(Flatten()) \nmodel_CNN.add(Dense(256)) \nmodel_CNN.add(LeakyReLU(alpha=0.1))            \nmodel_CNN.add(Dropout(0.5)) \n\n# LSTM Model\nmodel_lstm = Sequential()\nmodel_lstm.add(LSTM(units = 8, return_sequences = True, input_shape = (2500, 1), activation='tanh'))\nmodel_lstm.add(LSTM(units = 8, return_sequences = True))\nmodel_lstm.add(Dense(4, activation='tanh'))\nmodel_lstm.add(Dropout(0.2))\nmodel_lstm.add(Flatten())\n\n# Combine CNN and LSTM model\n#nb_classes = len(class_names)\nnb = 7\ncombined = concatenate([model_CNN.output, model_lstm.output], axis=-1)\noutput = Dense(nb, activation='softmax')(combined)\nmodel_final = Model(inputs=[model_CNN.input, model_lstm.input], outputs=output)\n\n# Plot and compile the model\nplot_model(model_final, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n\nmodel_final.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Callbacks\ncsv_logger = CSVLogger('training.log', separator=',', append=False)\nmc = ModelCheckpoint('CNN_LSTM.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n\n# Training\ntime1 = time.time()\nhistory = model_final.fit([train_images_cnn, train_images_lstm], \n                          train_labels_lstm,\n                          batch_size=1000,\n                          epochs=1, \n                          validation_data=([test_images_cnn, test_images_lstm],\n                                           test_labels_lstm), \n                          callbacks=[mc, csv_logger])\nprint ((\"Training time=\", time.time()-time1))\n\n# Save training history\nnp.save(\"CNN_LSTM_history.npy\", history.history)\n -->","metadata":{"execution":{"iopub.status.busy":"2024-02-05T08:39:31.893944Z","iopub.execute_input":"2024-02-05T08:39:31.894309Z","iopub.status.idle":"2024-02-05T08:42:07.616107Z","shell.execute_reply.started":"2024-02-05T08:39:31.894281Z","shell.execute_reply":"2024-02-05T08:42:07.615102Z"}}},{"cell_type":"markdown","source":"# Model Analytics\n","metadata":{}},{"cell_type":"code","source":"from keras.models import load_model\nfashion_model = load_model('./CNN_LSTM.h5') # load model\nfashion_model.summary() # summarize model.\n\nfrom contextlib import redirect_stdout\nwith open('./CNN_LSTM'+\".xls\", 'w') as f:\n    with redirect_stdout(f):\n        fashion_model.summary()\n        \nval_loss, val_accuracy=fashion_model.evaluate([test_images_cnn, test_images_lstm] ,test_labels_cnn) ## to get test accuracy and losses\nprint(val_loss, val_accuracy)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time2=time.time()\npredict_prob=fashion_model.predict([test_images_cnn, test_images_lstm])\ny_pred=np.argmax(predict_prob,axis=1)\nprint ('classification time:', time.time()-time2)\n\n##print (y_pred)\ny_true=np.argmax(test_labels_cnn, axis=1)\nfrom sklearn.metrics import precision_recall_fscore_support as score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import classification_report, confusion_matrix\ncm = confusion_matrix(y_true, y_pred)\nprint (cm)\nprint(classification_report(y_true, y_pred))\n\nprecision = precision_score(y_true, y_pred, average='weighted')\nprint('Precision: %f' % precision)\n# recall: tp / (tp + fn)\nrecall = recall_score(y_true, y_pred, average='weighted')\nprint('Recall: %f' % recall)\n# f1: tp / (tp + fp + fn)\nf1 = f1_score(y_true, y_pred, average='weighted')\nprint('F1 score: %f' % f1)\n#-----------  IoU\nfrom sklearn.metrics import jaccard_score\nprint ('IoU:', jaccard_score(y_true, y_pred, average='micro'))\n\n\ntest_eval = fashion_model.evaluate([test_images_cnn, test_images_lstm], test_labels_cnn)\n\nloss, accuracy = fashion_model.evaluate([train_images_cnn, train_images_lstm], train_labels_cnn)\nprint('loss_train: ', loss, 'accuracy_train: ', accuracy)\nprint('Test loss:', test_eval[0], 'Test accuracy:', test_eval[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nhistory_dict=history.history\nloss_values=history_dict['loss']\nval_loss_values=history_dict['val_loss']\nacc_values=history_dict['accuracy']\nval_acc_values=history_dict['val_accuracy']\nepochs=range(1, len(acc_values)+1)\ndef smooth_curve(points, factor=0.8):\n    smoothed_points = []\n    for point in points:\n        if smoothed_points:\n            previous = smoothed_points[-1]\n            smoothed_points.append(previous * factor + point * (1 - factor))\n        else:\n            smoothed_points.append(point)\n    return smoothed_points\nloss_values=smooth_curve(loss_values)\nval_loss_values=smooth_curve(val_loss_values)\nacc_values=smooth_curve(acc_values)\nval_acc_values=smooth_curve(val_acc_values)\n\nfont = {'family' : 'serif',\n        'color'  : 'black',\n        'weight' : 'normal',\n        'size'   : 12}\n        \n\nplt.plot(epochs, acc_values, 'r-', label='Training acc')\nplt.plot(epochs, val_acc_values, 'g', label='Validation acc')\nplt.title('Training and Validation acc', fontdict=font)\nplt.xlabel('Epochs', fontdict=font)\nplt.ylabel('Accuracy', fontdict=font)\nplt.legend()\nplt.savefig(\"accuracy\"+'CNN_LSTM'+\".png\")\nplt.show()\n\nplt.plot(epochs, loss_values, 'b-', label='Training loss')\nplt.plot(epochs, val_loss_values, 'r', label='Validation loss')\nplt.title('Training and Validation loss', fontdict=font)\nplt.xlabel('Epochs',fontdict=font)\nplt.ylabel('Loss',fontdict=font)\nplt.legend()\nplt.savefig(\"loss\"+'CNN_LSTM'+\".png\")\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = ['Fighting', 'Shoplifting', 'Abuse', 'Arrest', 'Shooting', 'Robbery', 'Explosion']\n# train_dir = '/kaggle/input/ucf-crime-dataset/Train'\n# class_names = os.listdir(train_dir)\n\n\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n#    classes = classes[unique_labels(y_true, y_pred)]\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    fig, ax = plt.subplots(figsize=(10, 10))\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax\n\nfont = {'family' : 'serif',\n        'color'  : 'black',\n        'weight' : 'normal',\n        'size'   : 14}\n\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplot_confusion_matrix(y_true, y_pred, classes=class_names,\n                      title='Confusion matrix, without normalization')\nplt.savefig('confusion matrix1'+'CNN_LSTM'+'.png')\nplt.show()\n# Plot normalized confusion matrix\nplot_confusion_matrix(y_true, y_pred, classes=class_names, normalize=True,\n                      title='Normalized confusion matrix')\nplt.savefig('confusion matrix2'+'CNN_LSTM'+'.png')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}